{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import sys\n",
    " \n",
    "def generar_excel_by_df(df, nombre_base):\n",
    "    \"\"\"\n",
    "    Genera un archivo Excel a partir de un DataFrame, añadiendo la fecha y hora actual al nombre del archivo.\n",
    "\n",
    "    :param df: DataFrame a exportar.\n",
    "    :param nombre_base: Nombre base del archivo (sin extensión).\n",
    "    :return: Ruta completa del archivo generado.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Obtener la fecha y hora actuales en formato 'YYYYMMDD_HHMMSS'\n",
    "        fecha_hora = datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "        \n",
    "        # Construir el nombre del archivo\n",
    "        nombre_archivo = f\"{nombre_base}_{fecha_hora}.xlsx\"\n",
    "        \n",
    "        # Exportar el DataFrame a Excel\n",
    "        df.to_excel(nombre_archivo, index=False, engine=\"openpyxl\")\n",
    "        \n",
    "        print(f\"Archivo Excel generado exitosamente: {nombre_archivo}\")\n",
    "        return nombre_archivo\n",
    "    except Exception as e:\n",
    "        print(f\"Error al generar el archivo Excel: {e}\")\n",
    "        return None\n",
    "\n",
    "def fusionar_archivos_excel(lista_archivos, hoja=None, nombre_salida=\"archivo_fusionado.xlsx\"):\n",
    "    \"\"\"\n",
    "    Fusiona múltiples archivos Excel en un solo archivo, permitiendo especificar una hoja de cada archivo.\n",
    "    \n",
    "    :param lista_archivos: Lista de rutas de los archivos Excel a fusionar.\n",
    "    :param hoja: Nombre de la hoja a leer de cada archivo. Si es None, se usará la primera hoja.\n",
    "    :param nombre_salida: Nombre del archivo de salida fusionado.\n",
    "    :return: Nombre del archivo fusionado, o una cadena vacía si no se pudieron procesar archivos.\n",
    "    \"\"\"\n",
    "    dataframes = []\n",
    "\n",
    "    for archivo in lista_archivos:\n",
    "        # Verificar si el archivo existe y tiene la extensión correcta\n",
    "        if os.path.isfile(archivo) and archivo.endswith(\".xlsx\"):\n",
    "            try:\n",
    "                # Leer el archivo con la hoja especificada\n",
    "                df = None\n",
    "                if hoja is None:\n",
    "                    df = pd.read_excel(archivo, engine=\"openpyxl\")\n",
    "                else:\n",
    "                    df = pd.read_excel(archivo, engine=\"openpyxl\", sheet_name=hoja)\n",
    "                \n",
    "\n",
    "                if df is not None:\n",
    "                   dataframes.append(df)\n",
    "            except ValueError:\n",
    "                print(f\"La hoja '{hoja}' no existe en el archivo {archivo}.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error al leer el archivo {archivo}: {e}\")\n",
    "        else:\n",
    "            print(f\"Archivo no válido o no encontrado: {archivo}\")\n",
    "\n",
    "    if dataframes:\n",
    "        # Concatenar los DataFrames si hay al menos uno válido\n",
    "        df_fusionado = pd.concat(dataframes, ignore_index=True)\n",
    "        # Especificar el motor openpyxl al guardar\n",
    "        df_fusionado.to_excel(nombre_salida, index=False, engine=\"openpyxl\")\n",
    "        return nombre_salida\n",
    "    else:\n",
    "        print(\"No se encontraron archivos válidos para fusionar.\")\n",
    "        return \"\"\n",
    "\n",
    "def listar_archivos_excel_por_cadena(directorio: str, cadena: str):\n",
    "    archivos_excel = []\n",
    "    patron = f\"*{cadena}*.xlsx\"\n",
    "    \n",
    "    for archivo in os.listdir(directorio):\n",
    "        if fnmatch.fnmatch(archivo, patron):\n",
    "            archivos_excel.append(archivo)\n",
    "\n",
    "    return archivos_excel\n",
    "\n",
    "def borrar_archivos(lista_archivos):\n",
    "    for archivo in lista_archivos:\n",
    "        if os.path.isfile(archivo):\n",
    "            try:\n",
    "                os.remove(archivo)\n",
    "                print(f\"Archivo eliminado: {archivo}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error al eliminar el archivo {archivo}: {e}\")\n",
    "        else:\n",
    "            print(f\"Archivo no encontrado: {archivo}\")\n",
    "\n",
    "def crear_dataframe_desde_archivo(archivo: str, columnas: list, hoja: str = None):\n",
    "\n",
    "    try:\n",
    "        # Leer el archivo completo usando pandas con la hoja especificada\n",
    "        df = None\n",
    "        if hoja is None:\n",
    "             df = pd.read_excel(archivo, engine='openpyxl')\n",
    "        else:\n",
    "             df = pd.read_excel(archivo, engine='openpyxl', sheet_name=hoja)\n",
    "\n",
    "        # Filtrar solo las columnas deseadas\n",
    "        df_filtrado = df[columnas]\n",
    "\n",
    "        return df_filtrado\n",
    "    except FileNotFoundError:\n",
    "        print(f\"El archivo {archivo} no fue encontrado.\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Una o más columnas no se encuentran en el archivo: {e}\")\n",
    "    except ValueError:\n",
    "        print(f\"La hoja '{hoja}' no existe en el archivo {archivo}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Se produjo un error al procesar el archivo: {e}\")\n",
    "\n",
    "def eliminar_columnas_df(dataframe, columnas):\n",
    "    \"\"\"\n",
    "    Elimina una lista de columnas de un DataFrame.\n",
    "\n",
    "    :param dataframe: DataFrame de pandas del que se desean eliminar las columnas.\n",
    "    :param columnas: Lista de nombres de columnas a eliminar.\n",
    "    :return: DataFrame con las columnas eliminadas.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Verificar cuáles columnas existen en el DataFrame\n",
    "        columnas_existentes = [col for col in columnas if col in dataframe.columns]\n",
    "        columnas_no_existentes = [col for col in columnas if col not in dataframe.columns]\n",
    "\n",
    "        if columnas_existentes:\n",
    "            dataframe = dataframe.drop(columns=columnas_existentes)\n",
    "            print(f\"Las columnas eliminadas exitosamente: {columnas_existentes}\")\n",
    "        \n",
    "        if columnas_no_existentes:\n",
    "            print(f\"Las siguientes columnas no existen en el DataFrame: {columnas_no_existentes}\")\n",
    "        \n",
    "        return dataframe\n",
    "    except Exception as e:\n",
    "        print(f\"Se produjo un error al intentar eliminar las columnas: {e}\")\n",
    "        return dataframe\n",
    "    \n",
    "def filtrar_columnas_df(dataframe, columnas):\n",
    "    \"\"\"\n",
    "    Devuelve un DataFrame que contiene solo las columnas especificadas.\n",
    "\n",
    "    :param dataframe: DataFrame de pandas del que se desea conservar las columnas.\n",
    "    :param columnas: Lista de nombres de columnas a conservar.\n",
    "    :return: DataFrame con solo las columnas especificadas.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Verificar cuáles columnas existen en el DataFrame\n",
    "        columnas_existentes = [col for col in columnas if col in dataframe.columns]\n",
    "        columnas_no_existentes = [col for col in columnas if col not in dataframe.columns]\n",
    "\n",
    "        if columnas_no_existentes:\n",
    "            print(f\"Las siguientes columnas no existen en el DataFrame: {columnas_no_existentes}\")\n",
    "\n",
    "        # Seleccionar solo las columnas existentes\n",
    "        dataframe = dataframe[columnas_existentes]\n",
    "\n",
    "        return dataframe\n",
    "    except Exception as e:\n",
    "        print(f\"Se produjo un error al intentar mantener las columnas: {e}\")\n",
    "        return dataframe\n",
    "    \n",
    "def reemplazar_ceros_con_nan(dataframe, columnas):\n",
    "    \"\"\"\n",
    "    Reemplaza ceros en las columnas especificadas de un DataFrame con NaN.\n",
    "\n",
    "    :param dataframe: DataFrame en el que se procesarán las columnas.\n",
    "    :param columnas: Lista de nombres de columnas donde se reemplazarán los ceros por NaN.\n",
    "    :return: DataFrame con los ceros reemplazados por NaN en las columnas especificadas.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validar que las columnas existan en el DataFrame\n",
    "        columnas_validas = [col for col in columnas if col in dataframe.columns]\n",
    "\n",
    "        # Reemplazar ceros por NaN en las columnas válidas\n",
    "        dataframe[columnas_validas] = dataframe[columnas_validas].replace(0, np.nan)\n",
    "\n",
    "        print(f\"Ceros reemplazados por NaN en las columnas: {columnas_validas}\")\n",
    "        return dataframe\n",
    "    except Exception as e:\n",
    "        print(f\"Error al reemplazar ceros por NaN: {e}\")\n",
    "        return dataframe\n",
    "    \n",
    "def crear_carpeta(base_nombre_carpeta, ruta_base=\".\"):\n",
    "    \"\"\"\n",
    "    Crea una carpeta con un nombre que incluye la fecha y hora actual al final.\n",
    "    \n",
    "    :param base_nombre_carpeta: Nombre base para la carpeta.\n",
    "    :param ruta_base: Ruta donde se creará la carpeta. Por defecto, en el directorio actual.\n",
    "    :return: Ruta completa de la carpeta creada.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Obtener la fecha y hora actuales en formato 'YYYY-MM-DDTHH-MM-SS'\n",
    "        fecha_hora = datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "        \n",
    "        # Construir el nombre completo de la carpeta\n",
    "        nombre_completo_carpeta = f\"{base_nombre_carpeta}_{fecha_hora}\"\n",
    "        ruta_completa_carpeta = os.path.join(ruta_base, nombre_completo_carpeta)\n",
    "        \n",
    "        # Crear la carpeta\n",
    "        os.makedirs(ruta_completa_carpeta, exist_ok=True)\n",
    "        print(f\"Carpeta creada: {ruta_completa_carpeta}\")\n",
    "        return ruta_completa_carpeta\n",
    "    except Exception as e:\n",
    "        print(f\"Error al crear la carpeta: {e}\")\n",
    "        return None\n",
    "\n",
    "def mover_archivos_a_carpeta(lista_archivos, carpeta_destino):\n",
    "    \"\"\"\n",
    "    Mueve una lista de archivos a una carpeta destino.\n",
    "    \n",
    "    :param lista_archivos: Lista con las rutas de los archivos a mover.\n",
    "    :param carpeta_destino: Ruta de la carpeta destino.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Crear la carpeta destino si no existe\n",
    "        carpeta_destino = crear_carpeta(carpeta_destino)\n",
    "        \n",
    "        for archivo in lista_archivos:\n",
    "            if os.path.isfile(archivo):  # Verificar que el archivo existe\n",
    "                destino = os.path.join(carpeta_destino, os.path.basename(archivo))  # Ruta destino\n",
    "                shutil.move(archivo, destino)  # Mover el archivo\n",
    "                print(f\"Archivo movido: {archivo} -> {destino}\")\n",
    "            else:\n",
    "                print(f\"El archivo no existe: {archivo}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al mover archivos: {e}\")\n",
    "\n",
    "def validar_archivos(lista_archivos):\n",
    "    \"\"\"\n",
    "    Valida que una lista de archivos no contenga valores vacíos.\n",
    "    \n",
    "    :param lista_archivos: Lista de rutas de archivos.\n",
    "    :return: True si todos los archivos son válidos, False si hay archivos faltantes.\n",
    "    \"\"\"\n",
    "    # Filtrar archivos vacíos\n",
    "    archivos_faltantes = [archivo for archivo in lista_archivos if archivo == \"\"]\n",
    "    \n",
    "    if archivos_faltantes:\n",
    "        print(\"Error: Faltan archivos necesarios para el proceso del reporte.\")\n",
    "        sys.exit(1)  # Rompe la ejecución con un código de error\n",
    "        return False\n",
    "    \n",
    "    print(\"Todos los archivos son válidos.\")\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "def crearDataframeExistenciaFinal(dfExistencias):\n",
    "    #Crea copia de DF de existencias para agrupación de existencias globales\n",
    "    dfExistenciasGrp = dfExistencias.copy(deep=True)\n",
    "    dfExistenciasGrp = filtrar_columnas_df(dfExistenciasGrp, [\"ProdConcat\", \"Existencia\"])\n",
    "    dfExistenciasGrpGlobal = dfExistenciasGrp.groupby('ProdConcat').agg({\n",
    "            'Existencia': 'sum'\n",
    "        }).reset_index()\n",
    "\n",
    "\n",
    "    # Realiza un PIVOT para los almacenes y calculos para agrupar los productos por ProdConcat\n",
    "    # Pivotar los datos para que cada Almacen tenga su propia columna\n",
    "    pivot = dfExistencias.pivot_table(\n",
    "        index=\"ProdConcat\", \n",
    "        columns=\"Almacen\", \n",
    "        values=\"Existencia\", \n",
    "        aggfunc=\"sum\"  # Sumamos si hay duplicados\n",
    "    )\n",
    "\n",
    "    # Renombrar las columnas del pivote agregando un prefijo\n",
    "    pivot = pivot.rename(columns=lambda col: f\"Existencias en {col}\")\n",
    "\n",
    "    # Resetear el índice del pivot\n",
    "    pivot.reset_index(inplace=True)\n",
    "\n",
    "    # Agrupar para obtener el primer valor de 'Nombre' y 'TipoProducto'\n",
    "    metadata = dfExistencias.groupby('ProdConcat').agg({\n",
    "        'Nombre': 'first',\n",
    "        'TipoProducto': 'first',\n",
    "        'Modelo': 'first',\n",
    "        'Marca': 'first',\n",
    "        \"Publico General\": 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Combinar el pivot con los datos adicionales\n",
    "    dfExistenciasAlmacenes = pd.merge(metadata, pivot, on=\"ProdConcat\", how=\"left\")\n",
    "\n",
    "    # #USAR dfExistenciasAlmacenes y dfExistenciasGrpGlobal para obtener datos limpios\n",
    "    dfExistenciasFinal =  pd.merge(dfExistenciasAlmacenes, dfExistenciasGrpGlobal, on=\"ProdConcat\", how=\"inner\")\n",
    "    return dfExistenciasFinal\n",
    "\n",
    "\n",
    "def creaReporteExistenciaConcentrada(dfExistenciasFinal):\n",
    "    dfConcentradoExistencias = dfExistenciasFinal.copy(deep=True)\n",
    "    dfConcentradoExistencias = eliminar_columnas_df(dfConcentradoExistencias, [\"ProdConcat\", \"TipoProducto\"])\n",
    "\n",
    "    # Reemplazar NaN con un valor predeterminado antes de agrupar\n",
    "    dfConcentradoExistencias[[\"Marca\", \"Modelo\", \"Nombre\"]] = dfConcentradoExistencias[[\"Marca\", \"Modelo\", \"Nombre\"]].fillna(\"Desconocido\")\n",
    "\n",
    "    dfConcentradoExistencias = dfConcentradoExistencias.groupby([\"Marca\", \"Modelo\", \"Nombre\"]).agg({\n",
    "        'Existencias en Central Cell 20 de noviembre': 'sum',\n",
    "        'Existencias en Central Cell Almacén general': 'sum',\n",
    "        'Existencias en Central Cell Abastos': 'sum',\n",
    "        'Existencias en Central Cell Fortín': 'sum',\n",
    "        'Existencias en Central Cell Labotienda': 'sum',\n",
    "        'Existencias en Central Cell Nuño del Mercado': 'sum',\n",
    "        'Existencias en Central Cell Plaza Bella': 'sum',\n",
    "        'Existencias en Central Cell Plaza Bonn': 'sum',\n",
    "        'Existencias en Central Cell Reforma': 'sum',\n",
    "        'Existencias en Central Cell Revistería': 'sum',\n",
    "        'Existencias en Central Cell Violetas': 'sum',\n",
    "        'Existencia': 'sum'\n",
    "    }).reset_index()\n",
    "        # Renombrar columnas del DataFrame\n",
    "    dfPiezasConsumidas.rename(columns={\n",
    "        \"Nombre\": \"Clasificación\"\n",
    "    }, inplace=True)\n",
    "\n",
    "\n",
    "    generar_excel_by_df(dfConcentradoExistencias, \"BI-CONCENTRADO-EXISTENCIAS-BY-MODELO-MARCA\")\n",
    "\n",
    "\n",
    "\n",
    "def creaDataFrameExistenciasComprasFinal(dfExistenciasFinal, dfCompras):\n",
    "    dfComprasAdjusted = dfCompras.copy(deep=True)\n",
    "    dfComprasAdjusted = eliminar_columnas_df(dfComprasAdjusted, [\"Almacen\"])\n",
    "    #Agrupa los datos de compras para limpiar la muestra\n",
    "    # Paso 1: Transformar la columna Fecha para que solo contenga la fecha sin la hora\n",
    "    dfComprasAdjusted[\"Fecha\"] = pd.to_datetime(dfComprasAdjusted[\"Fecha\"]).dt.date\n",
    "    # Paso 2: Filtrar los registros con la fecha más reciente por producto\n",
    "    # Ordenar el DataFrame por Producto y Fecha en orden descendente\n",
    "    dfComprasAdjusted = dfComprasAdjusted.sort_values(by=[\"Producto\", \"Fecha\"], ascending=[True, False])\n",
    "    # Mantener solo el registro más reciente para cada Producto\n",
    "    dfFiltradoCompras = dfComprasAdjusted.drop_duplicates(subset=\"Producto\", keep=\"first\")\n",
    "    dfFiltradoCompras.rename(columns={'Producto': 'ProdConcat'}, inplace=True)\n",
    "    #CASI LO FINAL\n",
    "    dfExistenciasComprasFinal =  pd.merge(dfExistenciasFinal, dfFiltradoCompras, on=\"ProdConcat\", how=\"left\")\n",
    "    dfExistenciasComprasFinal.rename(columns={'Existencia': 'Existencia Global', 'Fecha':'Última Fecha Compra', 'Costo':'Precio Compra', 'Cantidad':'Cantidad Comprada Ultimo Mov'}, inplace=True)\n",
    "    # Verificar si 'Publico General' es un DataFrame y corregir\n",
    "    if isinstance(dfExistenciasComprasFinal[\"Publico General\"], pd.DataFrame):\n",
    "        # Si es un DataFrame, tomar la primera columna válida (ajustar según necesidad)\n",
    "        dfExistenciasComprasFinal[\"Publico General\"] = dfExistenciasComprasFinal[\"Publico General\"].iloc[:, 0]\n",
    "    # Lista actual de columnas en el DataFrame\n",
    "    columnas_actuales = dfExistenciasComprasFinal.columns.tolist()\n",
    "    # Crear un nuevo orden, asegurando que no se dupliquen columnas\n",
    "    columnas_nuevo_orden = []\n",
    "    for col in columnas_actuales:\n",
    "        if col != \"Publico General\" and col != \"Cantidad Comprada Ultimo Mov\":  # Evitar duplicar la columna en su posición original\n",
    "            columnas_nuevo_orden.append(col)\n",
    "        if col == \"Precio Compra\":  # Insertar \"Publico General\" después de \"Precio Compra\"\n",
    "            columnas_nuevo_orden.append(\"Publico General\")\n",
    "        if col == \"Última Fecha Compra\":\n",
    "            columnas_nuevo_orden.append(\"Cantidad Comprada Ultimo Mov\")\n",
    "    # Reorganizar las columnas del DataFrame\n",
    "    dfExistenciasComprasFinal = dfExistenciasComprasFinal[columnas_nuevo_orden]\n",
    "    dfExistenciasComprasFinal['Precio Compra'] = pd.to_numeric(dfExistenciasComprasFinal['Precio Compra'], errors='coerce')\n",
    "    IVA = .16\n",
    "    CIEN = 100\n",
    "    # Verificar que las columnas sean numéricas y manejar NaN\n",
    "    if pd.api.types.is_numeric_dtype(dfExistenciasComprasFinal[\"Publico General\"]) and pd.api.types.is_numeric_dtype(dfExistenciasComprasFinal[\"Precio Compra\"]):\n",
    "        # Rellenar NaN con 0 para evitar errores durante la resta\n",
    "        dfExistenciasComprasFinal[\"Publico General\"] = dfExistenciasComprasFinal[\"Publico General\"].fillna(0)\n",
    "        dfExistenciasComprasFinal[\"Precio Compra\"] = dfExistenciasComprasFinal[\"Precio Compra\"].fillna(0)\n",
    "        # Crear la columna 'Utilidad Bruta'\n",
    "        dfExistenciasComprasFinal['Costo'] = dfExistenciasComprasFinal[\"Precio Compra\"]+(dfExistenciasComprasFinal[\"Precio Compra\"]*IVA)\n",
    "        # Crear la columna 'Utilidad Bruta'\n",
    "        dfExistenciasComprasFinal['Utilidad'] = ((dfExistenciasComprasFinal[\"Publico General\"]-dfExistenciasComprasFinal['Costo'])/dfExistenciasComprasFinal['Publico General']) * CIEN\n",
    "        print(\"Columna 'Utilidad' y 'Costo' creada exitosamente.\")\n",
    "    else:\n",
    "        print(\"Error: Las columnas 'Publico General' y 'Precio Compra' deben ser numéricas.\")\n",
    "    # Lista actual de columnas en el DataFrame\n",
    "    columnas_actuales = dfExistenciasComprasFinal.columns.tolist()\n",
    "    # Crear un nuevo orden, asegurando que no se dupliquen columnas\n",
    "    columnas_nuevo_orden = []\n",
    "    for col in columnas_actuales:\n",
    "        if col != \"Costo\":  # Evitar duplicar la columna en su posición original\n",
    "            columnas_nuevo_orden.append(col)\n",
    "        if col == \"Precio Compra\": \n",
    "            columnas_nuevo_orden.append(\"Costo\")\n",
    "    # Reorganizar las columnas del DataFrame\n",
    "    dfExistenciasComprasFinal = dfExistenciasComprasFinal[columnas_nuevo_orden]\n",
    "    return dfExistenciasComprasFinal\n",
    "\n",
    "\n",
    "def creaDataFrameVentasFinal(dfVentas, dfPiezasConsumidas):\n",
    "    # Combinar dfVentas y dfPiezasConsumidas\n",
    "    dfVentas = pd.concat([dfVentas, dfPiezasConsumidas], ignore_index=True)\n",
    "    dfVentas[\"Cantidad\"] = dfVentas[\"Cantidad\"].fillna(0)\n",
    "    # Agrupar por 'Almacen' y 'ProdConcat', sumando las cantidades\n",
    "    dfVentas = dfVentas.groupby([\"Almacen\", \"ProdConcat\"], as_index=False).agg({\"Cantidad\": \"sum\"})\n",
    "\n",
    "\n",
    "    dfVentasTotales = dfVentas.copy(deep=True)\n",
    "\n",
    "    # Paso 1: Agrupar por 'ProdConcat' y 'Almacen' para sumar las cantidades\n",
    "    dfVentasAgrupado = dfVentas.groupby([\"ProdConcat\", \"Almacen\"]).agg({\"Cantidad\": \"sum\"}).reset_index()\n",
    "\n",
    "    # Paso 2: Pivoteo por 'ProdConcat' y 'Almacen'\n",
    "    pivotVentas = dfVentasAgrupado.pivot_table(\n",
    "        index=\"ProdConcat\", \n",
    "        columns=\"Almacen\", \n",
    "        values=\"Cantidad\", \n",
    "        aggfunc=\"sum\"  # Ya no debería ser necesario, pero lo dejamos por seguridad\n",
    "    )\n",
    "\n",
    "    # Paso 3: Renombrar las columnas del pivote agregando un prefijo\n",
    "    pivotVentas = pivotVentas.rename(columns=lambda col: f\"Ventas de {col}\")\n",
    "\n",
    "    # Paso 4: Convertir el índice del pivote a una columna para un DataFrame plano\n",
    "    dfVentasFinal = pivotVentas.reset_index()\n",
    "\n",
    "\n",
    "    dfVentasTotales = eliminar_columnas_df(dfVentasTotales, [\"Almacen\"])\n",
    "\n",
    "    dfVentasTotalesAgp = dfVentasTotales.groupby([\"ProdConcat\"]).agg({\"Cantidad\": \"sum\"}).reset_index()\n",
    "\n",
    "    # Merge de dfVentasFinal y dfVentasTotalesAgp por 'ProdConcat'\n",
    "    dfVentasFinalMerged = pd.merge(\n",
    "        dfVentasFinal, \n",
    "        dfVentasTotalesAgp, \n",
    "        on=\"ProdConcat\",  # Clave común\n",
    "        how=\"inner\"       # Tipo de merge (inner join)\n",
    "    )\n",
    "\n",
    "    dfVentasFinalMerged.rename(columns={ 'Cantidad':'Ventas Totales'}, inplace=True)\n",
    "    return dfVentasFinalMerged\n",
    "\n",
    "def creaReporteExistenciasComprasVentasCC(dfExistenciasComprasFinal, dfVentasFinalMerged):\n",
    "    # Merge de dfExistenciasComprasFinal y dfVentasFinalMerged por 'ProdConcat'\n",
    "    dfResultadoFinalBIData = pd.merge(\n",
    "        dfExistenciasComprasFinal,\n",
    "        dfVentasFinalMerged,\n",
    "        on=\"ProdConcat\",  # Clave común\n",
    "        how=\"left\"       # Tipo de merge (inner join)\n",
    "    )\n",
    "\n",
    "    generar_excel_by_df(dfResultadoFinalBIData, \"BI-EXISTENCIAS-COMPRAS-VENTAS-CC\")\n",
    "\n",
    "\n",
    "def convertir_columna_uppercase(df, columna=\"ProdConcat\"):\n",
    "    \"\"\"\n",
    "    Convierte todos los valores de una columna de un DataFrame a mayúsculas.\n",
    "\n",
    "    :param df: DataFrame que contiene la columna a transformar.\n",
    "    :param columna: Nombre de la columna que se desea convertir a mayúsculas. Por defecto, 'ProdConcat'.\n",
    "    :return: DataFrame con la columna transformada.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if columna not in df.columns:\n",
    "            raise ValueError(f\"La columna '{columna}' no existe en el DataFrame.\")\n",
    "\n",
    "        # Convertir la columna a mayúsculas\n",
    "        df[columna] = df[columna].str.upper()\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error al convertir la columna '{columna}' a mayúsculas: {e}\")\n",
    "        return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"####################################################\")\n",
    "print(\"Iniciando análisis de datos...\")\n",
    "\n",
    "directorio = \"./\"  # Directorio actual\n",
    "\n",
    "#Archivos de existencias de productos\n",
    "archivosExistencias = \"Existencia\"\n",
    "archivosExitenciasMap = listar_archivos_excel_por_cadena(directorio, archivosExistencias)\n",
    "\n",
    "#Archivos de datos de compras\n",
    "archivosCompras = \"Excel_Movimientos\"\n",
    "archivosComprasMap = listar_archivos_excel_por_cadena(directorio, archivosCompras)\n",
    "\n",
    "#Archivos de datos de ventas\n",
    "archivosVentas = \"Analisis de Ventas por Tickets\"\n",
    "archivosVentasMap = listar_archivos_excel_por_cadena(directorio, archivosVentas)\n",
    "\n",
    "#Archivos de datos de ventas\n",
    "archivosPiezasConsumidas = \"Excel_Reparaciones_Refacciones_Consumidas\"\n",
    "archivosPiezasConsumidasMap = listar_archivos_excel_por_cadena(directorio, archivosPiezasConsumidas)\n",
    "\n",
    "archivosTrabajados = archivosExitenciasMap+ archivosComprasMap+ archivosVentasMap + archivosPiezasConsumidasMap\n",
    "\n",
    "#Fusión de archvios clasificados por reportes\n",
    "existenciasCC = fusionar_archivos_excel(lista_archivos=archivosExitenciasMap, nombre_salida=\"ExistenciasCC.xlsx\")\n",
    "comprasCC = fusionar_archivos_excel(lista_archivos=archivosComprasMap, hoja=\"Detalle de movimientos\", nombre_salida=\"ComprasCC.xlsx\")\n",
    "ventasCC = fusionar_archivos_excel(lista_archivos=archivosVentasMap, nombre_salida=\"VentasCC.xlsx\")\n",
    "piezasConsumidasCC = fusionar_archivos_excel(lista_archivos=archivosPiezasConsumidasMap, nombre_salida=\"PiezasConsumidasCC.xlsx\")\n",
    "\n",
    "\n",
    "validar_archivos([existenciasCC, comprasCC, ventasCC, piezasConsumidasCC]) \n",
    "\n",
    "#Qué columnas ocupamos de cada paquete de archivos\n",
    "columnasExistencias = [\"Almacen\", \"ProdConcat\", \"Existencia\", \"Nombre\", \"TipoProducto\", \"Marca\", \"Modelo\", \"Publico General\"]\n",
    "columnasCompras = [\"Almacen\", \"Fecha\", \"Producto\", \"Costo\", \"Cantidad\"]\n",
    "columnasVentas = [\"Almacen\", \"ProdConcat\", \"Cantidad\"]\n",
    "columnasPiezasConsumidas = [\"Almacén Salida Reparación\", \"Producto\", \"Cantidad\"]\n",
    "\n",
    "#Generación de dataframe de existencias y ajustes por valores numéricos\n",
    "dfExistencias = crear_dataframe_desde_archivo(existenciasCC, columnasExistencias)\n",
    "dfExistencias = reemplazar_ceros_con_nan(dfExistencias, [\"Existencia\"])\n",
    "\n",
    "#Generación de dataframe de compras\n",
    "dfCompras = crear_dataframe_desde_archivo(comprasCC, columnasCompras)\n",
    "\n",
    "#Generación de dataframe de ventas\n",
    "dfVentas = crear_dataframe_desde_archivo(ventasCC, columnasVentas)\n",
    "\n",
    "#Generación de dataframe de piezas consumidas \n",
    "dfPiezasConsumidas = crear_dataframe_desde_archivo(piezasConsumidasCC, columnasPiezasConsumidas)\n",
    "# Renombrar columnas del DataFrame de piezas consumidas\n",
    "dfPiezasConsumidas.rename(columns={\n",
    "    \"Almacén Salida Reparación\": \"Almacen\",\n",
    "    \"Producto\": \"ProdConcat\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Eliminar filas duplicadas considerando todas las columnas\n",
    "# Este paso se comenta debido a que en una versión del reporte que saca plows\n",
    "# se detectaron piezas consumidas duplicadas por lo que se decidió no eliminar duplicados\n",
    "# sin embargo parece ser que actualmente esto ya no ocurre\n",
    "# dfPiezasConsumidas.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "dfVentas = convertir_columna_uppercase(dfVentas, \"ProdConcat\")\n",
    "dfExistencias = convertir_columna_uppercase(dfExistencias, \"ProdConcat\")\n",
    "dfPiezasConsumidas = convertir_columna_uppercase(dfPiezasConsumidas, \"ProdConcat\")\n",
    "dfCompras = convertir_columna_uppercase(dfCompras, \"Producto\")\n",
    "\n",
    "# Crea un un Dataframe que contenga los valores de existencias \n",
    "# por almacen en forma de columnas y en otra la existencia global\n",
    "dfExistenciasFinal = crearDataframeExistenciaFinal(dfExistencias)\n",
    "\n",
    "# Genera el primer reporte que dará como resultado el acumulado \n",
    "# de existencias de Productos dividido por MARCA-MODELO-CATEGORÍA \n",
    "# por sucursal y globalmente\n",
    "creaReporteExistenciaConcentrada(dfExistenciasFinal)\n",
    "\n",
    "# Crea un DataFrame que contiene las existencias de productos por almacén \n",
    "# (en columnas) y una columna con la existencia global total\n",
    "# a su vez, quedan agrupada la ultima compra hecha, junto con la fecha para cada uno de los productos\n",
    "dfExistenciasComprasFinal = creaDataFrameExistenciasComprasFinal(dfExistenciasFinal, dfCompras)\n",
    "generar_excel_by_df(dfExistenciasComprasFinal, \"BI-EXISTENCIA-CC\")\n",
    "\n",
    "# Fusiona los DataFrames de ventas y piezas consumidas, consolidando las \n",
    "# cantidades de productos vendidos por almacén y obteniendo un DataFrame \n",
    "# con el detalle completo de ventas\n",
    "dfVentasFinalMerged = creaDataFrameVentasFinal(dfVentas, dfPiezasConsumidas)\n",
    "generar_excel_by_df(dfVentasFinalMerged, \"BI-VENTAS-CC\")\n",
    "\n",
    "\n",
    "# Crea un reporte final que integra existencias, compras y ventas, \n",
    "# mostrando el desglose de productos por almacén, acumulados y ventas \n",
    "# globales, facilitando el análisis comparativo\n",
    "creaReporteExistenciasComprasVentasCC(dfExistenciasComprasFinal, dfVentasFinalMerged)\n",
    "\n",
    "\n",
    "# Reagrupar archivos y nuevos \n",
    "archivosCompilados = listar_archivos_excel_por_cadena(directorio, \"CC\")\n",
    "archivosBI = listar_archivos_excel_por_cadena(directorio, \"BI-\")\n",
    "\n",
    "archivosTrabajados = archivosTrabajados + archivosCompilados + archivosBI\n",
    "print(archivosTrabajados)\n",
    "mover_archivos_a_carpeta(archivosTrabajados, \"BI-DATA-CC\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
